# Path to config file for robot hand geometry
hand_geometry_filename = ../cfg/hand_geometry.cfg

# Path to config file for volume and image geometry
image_geometry_filename = ../cfg/image_geometry_12channels.cfg

# (OpenVINO) Path to directory that contains neural network parameters
model_file = ../models/openvino/two_views_12_channels_curv_axis.xml
weights_file = ../models/openvino/two_views_12_channels_curv_axis.bin
device = 0
batch_size = 64

# Preprocessing of point cloud
#   voxelize: if the cloud gets voxelized/downsampled
#   voxel_size: size of voxel
#   remove_outliers: if statistical outliers are removed from the cloud (used to remove noise)
#   workspace: workspace of the robot (dimensions of a cube centered at origin of point cloud)
#   camera_position: position of the camera from which the cloud was taken
#   sample_above_plane: only draws samples which do not belong to the table plane
#   refine_normals_k: if 0, do not refine. If > 0, this is the number of neighbors used for refinement.
#   centered_at_origin: if the object is centered at the origin
voxelize = 1
voxel_size = 0.003
remove_outliers = 0
workspace = -1.0 1.0 -1.0 1.0 -1.0 1.0
camera_position = 0 0 0
sample_above_plane = 0
normals_radius = 0.01
refine_normals_k = 0
centered_at_origin = 1

# Grasp candidate generation
#   num_samples: number of samples to be drawn from the point cloud
#   num_threads: number of CPU threads to be used
#   nn_radius: neighborhood search radius for the local reference frame estimation
#   num_orientations: number of robot hand orientations to evaluate
#   num_finger_placements: number of finger placements to evaluate
#   hand_axes: axes about which the point neighborhood gets rotated (0: approach, 1: binormal, 2: axis)
#              (see https://raw.githubusercontent.com/atenpas/gpd2/master/readme/hand_frame.png)
#   deepen_hand: if the hand is pushed forward onto the object
#   friction_coeff: angle of friction cone in degrees
#   min_viable: minimum number of points required on each side to be antipodal
num_samples = 100
num_threads = 4
nn_radius = 0.01
num_orientations = 8
num_finger_placements = 10
# hand_axes = 0 1 2
# hand_axes = 0
# hand_axes = 1
hand_axes = 2
deepen_hand = 1
friction_coeff = 20
min_viable = 6

# Filtering of grasp candidates
#   min_aperture: minimum gripper width
#   max_aperture: maximum gripper width
#   workspace_grasps: dimensions of a cube centered at origin of point cloud; should be smaller than <workspace>
min_aperture = 0.0
max_aperture = 0.085
workspace_grasps = -1 1 -1 1 -1 1

# Filtering of grasp candidates based on their approach direction
#   filter_approach_direction: turn filtering on/off
#   direction: direction to compare against
#   angle_thresh: angle in radians above which grasps are filtered
filter_approach_direction = 0
direction = 1 0 0
thresh_rad = 2.0

# Clustering of grasps
#   min_inliers: minimum number of inliers per cluster; set to 0 to turn off clustering
min_inliers = 1

# Grasp selection
#   num_selected: number of selected grasps (sorted by score)
num_selected = 50

# Visualization
#   plot_normals: plot the surface normals
#   plot_samples: plot the samples
#   plot_candidates: plot the grasp candidates
#   plot_filtered_candidates: plot the grasp candidates which remain after filtering
#   plot_valid_grasps: plot the candidates that are identified as valid grasps
#   plot_clustered_grasps: plot the grasps that after clustering
#   plot_selected_grasps: plot the selected grasps (final output)
plot_normals = 0
plot_samples = 0
plot_candidates = 1
plot_filtered_candidates = 0
plot_valid_grasps = 1
plot_clustered_grasps = 0
plot_selected_grasps = 1
